---
title: "Future developers"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Future developers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = F
)


```


### Who should read this

If you a developer, and you want to build a similar dashboard, and want to understand why we used some technologies and those who taking on this project.


```{r setup}
library(DataTriangulationStream2)
```


You can install the development version of DataTriangulationStream2 from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("afenetgeeks/DataTriangulationStream2")
```


## Process of the Dashboard development 

First, most of parts of the dashboard were built using R and R shiny and hosted on the `shinyapps.io` servers, so then the app URL was used to integrate into the 3 platforms using an iframe.


### 1.	Data sources

The data sources used for this project are:

1.	DHIS2 National instance: 

- This is aggregated data and is collected via the web-api and it's updated monthly


2.	SORMAS (NCDC)

- This is case based data and each row is a case.

3.	Other sources available as csv files for the alternative denominator 


### 2.	Remote database 

The remote database is a cloud based SQL database that was aimed to store the combined data from Dhis2 and SORMAS to provide high scalability and reliability of the dashboard even if one of the data sources is down.

The remote database is an Aurora MySQL database on AWS (was developed using AWS console) and is updated by the `Anto-update database cloud server`. 

#### 2 i). Anto-update database cloud server 

This is a cloud server,which automatically pulls the data from `Dhis2` and combines it with `SORMAS` data and `alternative denominator` data and then updates the remote Database this is done once a month.

This is a server on AWS, it has Kubernetes (eks) which uses the docker containerized image to automatically pull the data from Dhis2 and updates the remote Database.
The Kubernetes Cronjobs were used to achieve the automation. The image is stored on the Aws ecr (Elastic Container Registry). 
To Build the Kubernetes cluster terraform was used to keep track of infrastructure as code.
Connecting to the Kubernetes cluster was done via aws cli and kubectl. 
The R scripts in the images are described below under R code and scripts section.


### 3. Shinyapps.io servers were used to host the dashboard.

Based on the dashboard architecture, deploying the dashboard on RStudio hosting services i.e., `shinyapps.io` was the best choice to use because about 70% (Note this number can change depending on the server configurations) of the users wonâ€™t need to pull data from the remote database directly, For example if they access the dashboard in the same time frame like of 5 minutes (Note this number can change depending on the server configurations) the remaining 30% users will pull the data directly from the database and therefore improving speed and performance.


### 4.	Integration without systems 

Since the dashboard is web-based technology, it gives us the ability to integrate with most of the already existing systems i.e `Dhis2`, `SORMAS`, and `MSDAT`  via an iframe since they also web-based technologies.

An iframe is an HTML tag i.e (a piece of code) like `<iframe> URL </iframe>`

**For the Dhis2 App**

Using the Dhis2 Application development platform, a custom Dhis2 app was developed to hold the `iframe`. A zipped folder was compiled containing the custom App, which was later uploaded to the Dhis2 instance via the App Management App in Dhis2.

### Developers taking on this extact project

Refer to the `Reference` tab on the website for documentation of the functions used in the project.


