---
title: "Future developers"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Future developers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = F
)
```


## Who should read this

If you are a developer and want to build a similar dashboard, or you are taking on this project and want to understand why and how we used some technologies, please get a cup of coffee.

## Where should you find the source code

Please access the code on this Github repo:

https://github.com/afenetgeeks/DataTriangulationStream2/

## Process of the Dashboard development 

*In summary*, 

Most of the dashboard parts were built using R and R shiny and hosted on the `shinyapps.io` servers, and its URL was used to integrate into the three platforms using an iframe.

And in the backend, Docker, Kubernetes, AWS and MySQL were used to pull and store data


### 1. Data sources

The data sources used for this project are:

1. DHIS2 National instance: 

- This is aggregated data and is collected via the web API, and it's updated monthly

2. SORMAS (NCDC)

- This is case-based data, and each row is a case.

- **NOTE:** Data which identifies the individual is **NOT** used at any level of the dashboard; the case ID, e.g. "TGDW5P", is used to identify the row in the database

3. Other sources available as CSV files for the alternative denominator 


### 2.	Remote database 

The remote database is a cloud-based SQL database aimed to store the combined data from DHIS2 and SORMAS to provide high scalability and reliability of the dashboard even if one of the data sources is down.

The remote database is an Aurora MySQL database on AWS (was developed using AWS console) and is updated by the `Anto-update database cloud server`. 

#### 2 i). Anto-update database cloud server 

This cloud server automatically pulls the data from `Dhis2` and combines it with `SORMAS` data and `alternative denominator` data and then updates the remote Database. This is done monthly.

This is a server on AWS; it has Kubernetes (EKS), which uses the docker containerized image to pull the data from Dhis2 automatically and updates the remote Database.
The Kubernetes Cronjobs were used to achieve automation. The image is stored on the AWS ERC (Elastic Container Registry). 
 
Terraform was used to build the Kubernetes cluster and keep track of infrastructure as code.
AWS cli and kubectl were used to connect to the Kubernetes cluster was done via 
The R scripts in the images are described below under the R code and scripts section.


### 3. Shinyapps.io servers were used to host the dashboard.

Based on the dashboard architecture, deploying the dashboard on RStudio hosting services, i.e., `shinyapps.io`, was the best choice to use because about 70% (Note this number can change depending on the server configurations) of the users wonâ€™t need to pull data from the remote database directly, For example, if they access the dashboard in the same time frame like of 5 minutes (Note this time frame can change depending on the server configurations) and therefore improving speed and performance.


### 4.	Integration without systems 

Since the dashboard is web-based technology, it allows us to integrate with most of the already existing systems, i.e. `Dhis2`, `SORMAS`, and `MSDAT`  via an iframe since they are also web-based technologies.

An iframe is an HTML tag, i.e. (a piece of code) like `<iframe> URL </iframe>`

**For the DHIS2 App**

Using the DHIS2 Application development platform, a custom DHIS2 app was developed to hold the `iframe`. A zipped folder was compiled containing the custom App, which was later uploaded to the DHIS2 instance via the App Management App in DHIS2.

### Developers taking on this extact project

Refer to the `Reference` tab on the website for documentation of the functions used in the project.


